{"edges": [{"edge": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "weight": 1, "attrs": {"_level": 0, "tags": ["Social and Information Networks", "Databases", "Physics and Society"], "date": "2024-01-16", "abstract": "Hypergraphs are a natural and powerful choice for modeling group interactions in the real world, which are often referred to as higher-order networks. For example, when modeling collaboration networks, where collaborations can involve not just two but three or more people, employing hypergraphs allows us to explore beyond pairwise (dyadic) patterns and capture groupwise (polyadic) patterns. The mathematical complexity of hypergraphs offers both opportunities and challenges for learning and mining on hypergraphs, and hypergraph mining, which seeks to enhance our understanding of underlying systems through hypergraph modeling, gained increasing attention in research. Researchers have discovered various structural patterns in real-world hypergraphs, leading to the development of mining tools. Moreover, they have designed generators with the aim of reproducing and thereby shedding light on these patterns. In this survey, we provide a comprehensive overview of the current landscape of hypergraph mining, covering patterns, tools, and generators. We provide comprehensive taxonomies for them, and we also provide in-depth discussions to provide insights into future research on hypergraph mining.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "weight": 1, "attrs": {"_level": 0, "tags": ["Computer Vision and Pattern Recognition"], "date": "2024-08-08", "abstract": "We introduce Hyper-YOLO, a new object detection method that integrates hypergraph computations to capture the complex high-order correlations among visual features. Traditional YOLO models, while powerful, have limitations in their neck designs that restrict the integration of cross-level features and the exploitation of high-order feature interrelationships. To address these challenges, we propose the Hypergraph Computation Empowered Semantic Collecting and Scattering (HGC-SCS) framework, which transposes visual feature maps into a semantic space and constructs a hypergraph for high-order message propagation. This enables the model to acquire both semantic and structural information, advancing beyond conventional feature-focused learning. Hyper-YOLO incorporates the proposed Mixed Aggregation Network (MANet) in its backbone for enhanced feature extraction and introduces the Hypergraph-Based Cross-Level and Cross-Position Representation Network (HyperC2Net) in its neck. HyperC2Net operates across five scales and breaks free from traditional grid structures, allowing for sophisticated high-order interactions across levels and positions. This synergy of components positions Hyper-YOLO as a state-of-the-art architecture in various scale models, as evidenced by its superior performance on the COCO dataset. Specifically, Hyper-YOLO-N significantly outperforms the advanced YOLOv8-N and YOLOv9-T with 12\\% $\\text{AP}^{val}$ and 9\\% $\\text{AP}^{val}$ improvements. The source codes are at ttps://github.com/iMoonLab/Hyper-YOLO.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications", "weight": 1, "attrs": {"_level": 0, "tags": ["Machine Learning", "Artificial Intelligence"], "date": "2024-09-09", "abstract": "Hypergraphs are increasingly utilized in both unimodal and multimodal data scenarios due to their superior ability to model and extract higher-order relationships among nodes, compared to traditional graphs. However, current hypergraph models are encountering challenges related to imbalanced data, as this imbalance can lead to biases in the model towards the more prevalent classes. While the existing techniques, such as GraphSMOTE, have improved classification accuracy for minority samples in graph data, they still fall short when addressing the unique structure of hypergraphs. Inspired by SMOTE concept, we propose HyperSMOTE as a solution to alleviate the class imbalance issue in hypergraph learning. This method involves a two-step process: initially synthesizing minority class nodes, followed by the nodes integration into the original hypergraph. We synthesize new nodes based on samples from minority classes and their neighbors. At the same time, in order to solve the problem on integrating the new node into the hypergraph, we train a decoder based on the original hypergraph incidence matrix to adaptively associate the augmented node to hyperedges. We conduct extensive evaluation on multiple single-modality datasets, such as Cora, Cora-CA and Citeseer, as well as multimodal conversation dataset MELD to verify the effectiveness of HyperSMOTE, showing an average performance gain of 3.38% and 2.97% on accuracy, respectively.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for $100\\times$ Faster Inference", "weight": 1, "attrs": {"_level": 0, "tags": ["Machine Learning"], "date": "2024-02-06", "abstract": "Hypergraph Neural Networks (HGNNs) have recently attracted much attention and exhibited satisfactory performance due to their superiority in high-order correlation modeling. However, it is noticed that the high-order modeling capability of hypergraph also brings increased computation complexity, which hinders its practical industrial deployment. In practice, we find that one key barrier to the efficient deployment of HGNNs is the high-order structural dependencies during inference. In this paper, we propose to bridge the gap between the HGNNs and inference-efficient Multi-Layer Perceptron (MLPs) to eliminate the hypergraph dependency of HGNNs and thus reduce computational complexity as well as improve inference speed. Specifically, we introduce LightHGNN and LightHGNN$^+$ for fast inference with low complexity. LightHGNN directly distills the knowledge from teacher HGNNs to student MLPs via soft labels, and LightHGNN$^+$ further explicitly injects reliable high-order correlations into the student MLPs to achieve topology-aware distillation and resistance to over-smoothing. Experiments on eight hypergraph datasets demonstrate that even without hypergraph dependency, the proposed LightHGNNs can still achieve competitive or even better performance than HGNNs and outperform vanilla MLPs by $16.3$ on average. Extensive experiments on three graph datasets further show the average best performance of our LightHGNNs compared with all other methods. Experiments on synthetic hypergraphs with 5.5w vertices indicate LightHGNNs can run $100\\times$ faster than HGNNs, showcasing their ability for latency-sensitive deployments.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "weight": 1, "attrs": {"_level": 0, "tags": ["Computer Vision and Pattern Recognition"], "date": "2024-03-14", "abstract": "Text-to-3D generation represents an exciting field that has seen rapid advancements, facilitating the transformation of textual descriptions into detailed 3D models. However, current progress often neglects the intricate high-order correlation of geometry and texture within 3D objects, leading to challenges such as over-smoothness, over-saturation and the Janus problem. In this work, we propose a method named ``3D Gaussian Generation via Hypergraph (Hyper-3DG)'', designed to capture the sophisticated high-order correlations present within 3D objects. Our framework is anchored by a well-established mainflow and an essential module, named ``Geometry and Texture Hypergraph Refiner (HGRefiner)''. This module not only refines the representation of 3D Gaussians but also accelerates the update process of these 3D Gaussians by conducting the Patch-3DGS Hypergraph Learning on both explicit attributes and latent visual features. Our framework allows for the production of finely generated 3D objects within a cohesive optimization, effectively circumventing degradation. Extensive experimentation has shown that our proposed method significantly enhances the quality of 3D generation while incurring no additional computational overhead for the underlying framework. (Project code: https://github.com/yjhboy/Hyper3DG)", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "weight": 1, "attrs": {"_level": 0, "tags": ["Social and Information Networks", "Spectral Theory", "Physics and Society"], "date": "2024-03-06", "abstract": "We propose a team assignment algorithm based on a hypergraph approach focusing on resilience and diffusion optimization. Specifically, our method is based on optimizing the algebraic connectivity of the Laplacian matrix of an edge-dependent vertex-weighted hypergraph. We used constrained simulated annealing, where we constrained the effort agents can exert to perform a task and the minimum effort a task requires to be completed. We evaluated our methods in terms of the number of unsuccessful patches to drive our solution into the feasible region and the cost of patching. We showed that our formulation provides more robust solutions than the original data and the greedy approach. We hope that our methods motivate further research in applying hypergraphs to similar problems in different research areas and in exploring variations of our methods.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hypergraph based Understanding for Document Semantic Entity Recognition", "weight": 1, "attrs": {"_level": 0, "tags": ["Artificial Intelligence"], "date": "2024-07-09", "abstract": "Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus on entity categories while ignoring the extraction of entity boundaries. We build a novel hypergraph attention document semantic entity recognition framework, HGA, which uses hypergraph attention to focus on entity boundaries and entity categories at the same time. It can conduct a more detailed analysis of the document text representation analyzed by the upstream model and achieves a better performance of semantic information. We apply this method on the basis of GraphLayoutLM to construct a new semantic entity recognition model HGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that our method can effectively improve the performance of semantic entity recognition tasks based on the original model. The results of HGALayoutLM on FUNSD and XFUND reach the new state-of-the-art results.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control", "weight": 1, "attrs": {"_level": 0, "tags": ["Multiagent Systems"], "date": "2024-09-08", "abstract": "Deep reinforcement learning (DRL) methods that incorporate graph neural networks (GNNs) have been extensively studied for intelligent traffic signal control, which aims to coordinate traffic signals effectively across multiple intersections. Despite this progress, the standard graph learning used in these methods still struggles to capture higher-order correlations in real-world traffic flow. In this paper, we propose a multi-agent proximal policy optimization framework DHG-PPO, which incorporates PPO and directed hypergraph module to extract the spatio-temporal attributes of the road networks. DHG-PPO enables multiple agents to ingeniously interact through the dynamical construction of hypergraph. The effectiveness of DHG-PPO is validated in terms of average travel time and throughput against state-of-the-art baselines through extensive experiments.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hypergraph-based Multi-View Action Recognition using Event Cameras", "weight": 1, "attrs": {"_level": 0, "tags": ["Computer Vision and Pattern Recognition", "Artificial Intelligence", "Machine Learning"], "date": "2024-03-28", "abstract": "Action recognition from video data forms a cornerstone with wide-ranging applications. Single-view action recognition faces limitations due to its reliance on a single viewpoint. In contrast, multi-view approaches capture complementary information from various viewpoints for improved accuracy. Recently, event cameras have emerged as innovative bio-inspired sensors, leading to advancements in event-based action recognition. However, existing works predominantly focus on single-view scenarios, leaving a gap in multi-view event data exploitation, particularly in challenges like information deficit and semantic misalignment. To bridge this gap, we introduce HyperMV, a multi-view event-based action recognition framework. HyperMV converts discrete event data into frame-like representations and extracts view-related features using a shared convolutional network. By treating segments as vertices and constructing hyperedges using rule-based and KNN-based strategies, a multi-view hypergraph neural network that captures relationships across viewpoint and temporal features is established. The vertex attention hypergraph propagation is also introduced for enhanced feature fusion. To prompt research in this area, we present the largest multi-view event-based action dataset $\\text{THU}^{\\text{MV-EACT}}\\text{-50}$, comprising 50 actions from 6 viewpoints, which surpasses existing datasets by over tenfold. Experimental results show that HyperMV significantly outperforms baselines in both cross-subject and cross-view scenarios, and also exceeds the state-of-the-arts in frame-based multi-view action recognition.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Multimodal Fusion via Hypergraph Autoencoder and Contrastive Learning for Emotion Recognition in Conversation", "weight": 1, "attrs": {"_level": 0, "tags": ["Multimedia"], "date": "2024-08-01", "abstract": "Multimodal emotion recognition in conversation (MERC) seeks to identify the speakers' emotions expressed in each utterance, offering significant potential across diverse fields. The challenge of MERC lies in balancing speaker modeling and context modeling, encompassing both long-distance and short-distance contexts, as well as addressing the complexity of multimodal information fusion. Recent research adopts graph-based methods to model intricate conversational relationships effectively. Nevertheless, the majority of these methods utilize a fixed fully connected structure to link all utterances, relying on convolution to interpret complex context. This approach can inherently heighten the redundancy in contextual messages and excessive graph network smoothing, particularly in the context of long-distance conversations. To address this issue, we propose a framework that dynamically adjusts hypergraph connections by variational hypergraph autoencoder (VHGAE), and employs contrastive learning to mitigate uncertainty factors during the reconstruction process. Experimental results demonstrate the effectiveness of our proposal against the state-of-the-art methods on IEMOCAP and MELD datasets. We release the code to support the reproducibility of this work at https://github.com/yzjred/-HAUCL.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "weight": 1, "attrs": {"_level": 0, "tags": ["Machine Learning"], "date": "2024-04-01", "abstract": "Higher-order interactions (HOIs) are ubiquitous in real-world complex systems and applications. Investigation of deep learning for HOIs, thus, has become a valuable agenda for the data mining and machine learning communities. As networks of HOIs are expressed mathematically as hypergraphs, hypergraph neural networks (HNNs) have emerged as a powerful tool for representation learning on hypergraphs. Given the emerging trend, we present the first survey dedicated to HNNs, with an in-depth and step-by-step guide. Broadly, the present survey overviews HNN architectures, training strategies, and applications. First, we break existing HNNs down into four design components: (i) input features, (ii) input structures, (iii) message-passing schemes, and (iv) training strategies. Second, we examine how HNNs address and learn HOIs with each of their components. Third, we overview the recent applications of HNNs in recommendation, bioinformatics and medical science, time series analysis, and computer vision. Lastly, we conclude with a discussion on limitations and future directions.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "weight": 1, "attrs": {"_level": 0, "tags": ["Computer Vision and Pattern Recognition"], "date": "2024-07-10", "abstract": "Understanding of video creativity and content often varies among individuals, with differences in focal points and cognitive levels across different ages, experiences, and genders. There is currently a lack of research in this area, and most existing benchmarks suffer from several drawbacks: 1) a limited number of modalities and answers with restrictive length; 2) the content and scenarios within the videos are excessively monotonous, transmitting allegories and emotions that are overly simplistic. To bridge the gap to real-world applications, we introduce a large-scale Subjective Response Indicators for Advertisement Videos dataset, namely SRI-ADV. Specifically, we collected real changes in Electroencephalographic (EEG) and eye-tracking regions from different demographics while they viewed identical video content. Utilizing this multi-modal dataset, we developed tasks and protocols to analyze and evaluate the extent of cognitive understanding of video content among different users. Along with the dataset, we designed a Hypergraph Multi-modal Large Language Model (HMLLM) to explore the associations among different demographics, video elements, EEG, and eye-tracking indicators. HMLLM could bridge semantic gaps across rich modalities and integrate information beyond different modalities to perform logical reasoning. Extensive experimental evaluations on SRI-ADV and other additional video-based generative performance benchmarks demonstrate the effectiveness of our method. The codes and dataset will be released at https://github.com/mininglamp-MLLM/HMLLM.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "weight": 1, "attrs": {"_level": 0, "tags": ["Machine Learning"], "date": "2024-03-31", "abstract": "Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple nodes with hyperedges, and better capturing the topology is essential for effective representation learning. Recent advances in generative self-supervised learning (SSL) suggest that hypergraph neural networks learned from generative self supervision have the potential to effectively encode the complex hypergraph topology. Designing a generative SSL strategy for hypergraphs, however, is not straightforward. Questions remain with regard to its generative SSL task, connection to downstream tasks, and empirical properties of learned representations. In light of the promises and challenges, we propose a novel generative SSL strategy for hypergraphs. We first formulate a generative SSL task on hypergraphs, hyperedge filling, and highlight its theoretical connection to node classification. Based on the generative SSL task, we propose a hypergraph SSL method, HypeBoy. HypeBoy learns effective general-purpose hypergraph representations, outperforming 16 baseline methods across 11 benchmark datasets.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hypergraph Dynamic System", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Hypergraph Isomorphism Computation", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-05-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "weight": 1, "attrs": {"_level": 0, "tags": ["Artificial Intelligence"], "date": "2024-10-13", "abstract": "Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by focusing mainly on pairwise relationships, overlooking the high-order correlations found in real-world data. Hypergraphs, which can model complex beyond-pairwise relationships, offer a more robust framework but are still underexplored in the context of LLMs. To address this gap, we introduce LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems across eight low-order, five high-order, and two isomorphism tasks, utilizing both synthetic and real-world hypergraphs from citation networks and protein structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our benchmark's effectiveness in identifying model strengths and weaknesses. Our specialized prompting framework incorporates seven hypergraph languages and introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance high-order reasoning and achieve an average 4% (up to 9%) performance improvement on structure classification tasks. This work establishes a foundational testbed for integrating hypergraph computational capabilities into LLMs, advancing their comprehension. The source codes are at https://github.com/iMoonLab/LLM4Hypergraph.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-05-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "A Survey on Hypergraph Representation Learning", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs", "weight": 1, "attrs": {"_level": 0, "tags": ["Multiagent Systems", "Artificial Intelligence"], "date": "2024-04-16", "abstract": "Traffic signal control systems (TSCSs) are integral to intelligent traffic management, fostering efficient vehicle flow. Traditional approaches often simplify road networks into standard graphs, which results in a failure to consider the dynamic nature of traffic data at neighboring intersections, thereby neglecting higher-order interconnections necessary for real-time control. To address this, we propose a novel TSCS framework to realize intelligent traffic control. This framework collaborates with multiple neighboring edge computing servers to collect traffic information across the road network. To elevate the efficiency of traffic signal control, we have crafted a multi-agent soft actor-critic (MA-SAC) reinforcement learning algorithm. Within this algorithm, individual agents are deployed at each intersection with a mandate to optimize traffic flow across the entire road network collectively. Furthermore, we introduce hypergraph learning into the critic network of MA-SAC to enable the spatio-temporal interactions from multiple intersections in the road network. This method fuses hypergraph and spatio-temporal graph structures to encode traffic data and capture the complex spatial and temporal correlations between multiple intersections. Our empirical evaluation, tested on varied datasets, demonstrates the superiority of our framework in minimizing average vehicle travel times and sustaining high-throughput performance. This work facilitates the development of more intelligent and reactive urban traffic management solutions.", "funding_agencies": [], "source": "Arxiv"}}, {"edge": "Hypergraph motifs and their extensions beyond binary", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-05-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Distributed constrained combinatorial optimization leveraging hypergraph neural networks", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Multi-Modal Temporal Hypergraph Neural Network for Flotation Condition Recognition", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-03-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Hypergraph-Based Multi-View Action Recognition Using Event Cameras", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-10-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Divide-Aggregate Heterogeneous Hypergraph for large-scale user intention detection", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Multi-View Time-Series Hypergraph Neural Network for Action Recognition", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-04-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Strong Consistency of Spectral Clustering for the Sparse Degree-Corrected Hypergraph Stochastic Block Model", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "weight": 1, "attrs": {"_level": 0, "tags": [], "date": "2024-01-01", "abstract": "", "funding_agencies": [], "source": "DBLP"}}], "nodes": [{"node": "Geon Lee", "weight": 1, "attrs": {"institutions": []}}, {"node": "Fanchen Bu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Tina Eliassi-Rad", "weight": 1, "attrs": {"institutions": []}}, {"node": "Kijung Shin", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yifan Feng", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jiangang Huang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Shaoyi Du", "weight": 1, "attrs": {"institutions": []}}, {"node": "Shihui Ying", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jun-Hai Yong", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yipeng Li", "weight": 1, "attrs": {"institutions": []}}, {"node": "Guiguang Ding", "weight": 1, "attrs": {"institutions": []}}, {"node": "Rongrong Ji", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yue Gao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Ziming Zhao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Tiehua Zhang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zijian Yi", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zhishu Shen", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yihe Luo", "weight": 1, "attrs": {"institutions": []}}, {"node": "Donglin Di", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jiahui Yang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Chaofan Luo", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zhou Xue", "weight": 1, "attrs": {"institutions": []}}, {"node": "Wei Chen", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xun Yang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Guilherme Ferraz de Arruda", "weight": 1, "attrs": {"institutions": []}}, {"node": "Wan He", "weight": 1, "attrs": {"institutions": []}}, {"node": "Nasimeh Heydaribeni", "weight": 1, "attrs": {"institutions": []}}, {"node": "Tara Javidi", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yamir Moreno", "weight": 1, "attrs": {"institutions": []}}, {"node": "Qiwei Li", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zuchao Li", "weight": 1, "attrs": {"institutions": []}}, {"node": "Ping Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Haojun Ai", "weight": 1, "attrs": {"institutions": []}}, {"node": "Hai Zhao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Kang Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zhenwei Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jiaxuan Lu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Siqi Li", "weight": 1, "attrs": {"institutions": []}}, {"node": "Sunwoo Kim", "weight": 1, "attrs": {"institutions": []}}, {"node": "Soo Yong Lee", "weight": 1, "attrs": {"institutions": []}}, {"node": "Alessia Antelmi", "weight": 1, "attrs": {"institutions": []}}, {"node": "Mirko Polato", "weight": 1, "attrs": {"institutions": []}}, {"node": "Minghui Wu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Chenxu Zhao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Anyang Su", "weight": 1, "attrs": {"institutions": []}}, {"node": "Tianyu Fu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Da An", "weight": 1, "attrs": {"institutions": []}}, {"node": "Min He", "weight": 1, "attrs": {"institutions": []}}, {"node": "Ya Gao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Meng Ma", "weight": 1, "attrs": {"institutions": []}}, {"node": "Kun Yan", "weight": 1, "attrs": {"institutions": []}}, {"node": "Shinhwan Kang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jaemin Yoo", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jielong Yan", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jiashu Han", "weight": 1, "attrs": {"institutions": []}}, {"node": "Chengwu Yang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xingliang Hou", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zongze Wu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Hao Zhong", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yubo Zhang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Chenggang Yan", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zuxing Xuan", "weight": 1, "attrs": {"institutions": []}}, {"node": "Ting Yu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Ji Zhang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Gennaro Cordasco", "weight": 1, "attrs": {"institutions": []}}, {"node": "Vittorio Scarano", "weight": 1, "attrs": {"institutions": []}}, {"node": "Carmine Spagnuolo", "weight": 1, "attrs": {"institutions": []}}, {"node": "Dingqi Yang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zhen Lei", "weight": 1, "attrs": {"institutions": []}}, {"node": "Seokbum Yoon", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jihoon Ko", "weight": 1, "attrs": {"institutions": []}}, {"node": "Hyunju Kim", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xinrui Zhan", "weight": 1, "attrs": {"institutions": []}}, {"node": "Ruisi Zhang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Farinaz Koushanfar", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zunguan Fan", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xiaoli Li", "weight": 1, "attrs": {"institutions": []}}, {"node": "Mingcheng Qu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xianyang Song", "weight": 1, "attrs": {"institutions": []}}, {"node": "Tonghua Su", "weight": 1, "attrs": {"institutions": []}}, {"node": "Nan Ma", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zhixuan Wu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Cheng Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Shuyi Ji", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yu-Shen Liu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Qionghai Dai", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yuze Liu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xin Chen", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xiaowei Huang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jun Yin", "weight": 1, "attrs": {"institutions": []}}, {"node": "Bingjun Luo", "weight": 1, "attrs": {"institutions": []}}, {"node": "Haowen Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Jinpeng Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Junjie Zhu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xibin Zhao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Lu Jiang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yanan Xiao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xinxin Zhao", "weight": 1, "attrs": {"institutions": []}}, {"node": "Yuanbo Xu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Shuli Hu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Pengyang Wang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Minghao Yin", "weight": 1, "attrs": {"institutions": []}}, {"node": "Chong Deng", "weight": 1, "attrs": {"institutions": []}}, {"node": "Xin-Jian Xu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Zhaofan Zhang", "weight": 1, "attrs": {"institutions": []}}, {"node": "Cheng Xu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Genbao Xu", "weight": 1, "attrs": {"institutions": []}}, {"node": "Mingxing Li", "weight": 1, "attrs": {"institutions": []}}], "incidences": [{"edge": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "node": "Geon Lee", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "node": "Fanchen Bu", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "node": "Tina Eliassi-Rad", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "node": "Kijung Shin", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Jiangang Huang", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Shaoyi Du", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Jun-Hai Yong", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Yipeng Li", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Guiguang Ding", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Rongrong Ji", "weight": 1, "attrs": {}}, {"edge": "Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications", "node": "Ziming Zhao", "weight": 1, "attrs": {}}, {"edge": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications", "node": "Tiehua Zhang", "weight": 1, "attrs": {}}, {"edge": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications", "node": "Zijian Yi", "weight": 1, "attrs": {}}, {"edge": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications", "node": "Zhishu Shen", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for $100\\times$ Faster Inference", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for $100\\times$ Faster Inference", "node": "Yihe Luo", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for $100\\times$ Faster Inference", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for $100\\times$ Faster Inference", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Donglin Di", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Jiahui Yang", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Chaofan Luo", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Zhou Xue", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Wei Chen", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Xun Yang", "weight": 1, "attrs": {}}, {"edge": "Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "node": "Guilherme Ferraz de Arruda", "weight": 1, "attrs": {}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "node": "Wan He", "weight": 1, "attrs": {}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "node": "Nasimeh Heydaribeni", "weight": 1, "attrs": {}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "node": "Tara Javidi", "weight": 1, "attrs": {}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "node": "Yamir Moreno", "weight": 1, "attrs": {}}, {"edge": "Assigning Entities to Teams as a Hypergraph Discovery Problem", "node": "Tina Eliassi-Rad", "weight": 1, "attrs": {}}, {"edge": "Hypergraph based Understanding for Document Semantic Entity Recognition", "node": "Qiwei Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph based Understanding for Document Semantic Entity Recognition", "node": "Zuchao Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph based Understanding for Document Semantic Entity Recognition", "node": "Ping Wang", "weight": 1, "attrs": {}}, {"edge": "Hypergraph based Understanding for Document Semantic Entity Recognition", "node": "Haojun Ai", "weight": 1, "attrs": {}}, {"edge": "Hypergraph based Understanding for Document Semantic Entity Recognition", "node": "Hai Zhao", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control", "node": "Kang Wang", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control", "node": "Zhishu Shen", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control", "node": "Zhenwei Wang", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control", "node": "Tiehua Zhang", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-based Multi-View Action Recognition using Event Cameras", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-based Multi-View Action Recognition using Event Cameras", "node": "Jiaxuan Lu", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-based Multi-View Action Recognition using Event Cameras", "node": "Siqi Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-based Multi-View Action Recognition using Event Cameras", "node": "Yipeng Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-based Multi-View Action Recognition using Event Cameras", "node": "Shaoyi Du", "weight": 1, "attrs": {}}, {"edge": "Multimodal Fusion via Hypergraph Autoencoder and Contrastive Learning for Emotion Recognition in Conversation", "node": "Zijian Yi", "weight": 1, "attrs": {}}, {"edge": "Multimodal Fusion via Hypergraph Autoencoder and Contrastive Learning for Emotion Recognition in Conversation", "node": "Ziming Zhao", "weight": 1, "attrs": {}}, {"edge": "Multimodal Fusion via Hypergraph Autoencoder and Contrastive Learning for Emotion Recognition in Conversation", "node": "Zhishu Shen", "weight": 1, "attrs": {}}, {"edge": "Multimodal Fusion via Hypergraph Autoencoder and Contrastive Learning for Emotion Recognition in Conversation", "node": "Tiehua Zhang", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "node": "Sunwoo Kim", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "node": "Soo Yong Lee", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "node": "Alessia Antelmi", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "node": "Mirko Polato", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide", "node": "Kijung Shin", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Minghui Wu", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Chenxu Zhao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Anyang Su", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Donglin Di", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Tianyu Fu", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Da An", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Min He", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Ya Gao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Meng Ma", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Kun Yan", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Multi-modal Large Language Model: Exploiting EEG and Eye-tracking Modalities to Evaluate Heterogeneous Responses for Video Understanding", "node": "Ping Wang", "weight": 1, "attrs": {}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "node": "Sunwoo Kim", "weight": 1, "attrs": {}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "node": "Shinhwan Kang", "weight": 1, "attrs": {}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "node": "Fanchen Bu", "weight": 1, "attrs": {}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "node": "Soo Yong Lee", "weight": 1, "attrs": {}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "node": "Jaemin Yoo", "weight": 1, "attrs": {}}, {"edge": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs", "node": "Kijung Shin", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Dynamic System", "node": "Jielong Yan", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Dynamic System", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Dynamic System", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Dynamic System", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Isomorphism Computation", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Isomorphism Computation", "node": "Jiashu Han", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Isomorphism Computation", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "Hypergraph Isomorphism Computation", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Chengwu Yang", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Xingliang Hou", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Shaoyi Du", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Zongze Wu", "weight": 1, "attrs": {}}, {"edge": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Hao Zhong", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Yubo Zhang", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Chenggang Yan", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Zuxing Xuan", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Ting Yu", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Ji Zhang", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "Penalized Flow Hypergraph Local Clustering", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Representation Learning", "node": "Alessia Antelmi", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Representation Learning", "node": "Gennaro Cordasco", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Representation Learning", "node": "Mirko Polato", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Representation Learning", "node": "Vittorio Scarano", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Representation Learning", "node": "Carmine Spagnuolo", "weight": 1, "attrs": {}}, {"edge": "A Survey on Hypergraph Representation Learning", "node": "Dingqi Yang", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs", "node": "Kang Wang", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs", "node": "Zhishu Shen", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs", "node": "Zhen Lei", "weight": 1, "attrs": {}}, {"edge": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs", "node": "Tiehua Zhang", "weight": 1, "attrs": {}}, {"edge": "Hypergraph motifs and their extensions beyond binary", "node": "Geon Lee", "weight": 1, "attrs": {}}, {"edge": "Hypergraph motifs and their extensions beyond binary", "node": "Seokbum Yoon", "weight": 1, "attrs": {}}, {"edge": "Hypergraph motifs and their extensions beyond binary", "node": "Jihoon Ko", "weight": 1, "attrs": {}}, {"edge": "Hypergraph motifs and their extensions beyond binary", "node": "Hyunju Kim", "weight": 1, "attrs": {}}, {"edge": "Hypergraph motifs and their extensions beyond binary", "node": "Kijung Shin", "weight": 1, "attrs": {}}, {"edge": "Distributed constrained combinatorial optimization leveraging hypergraph neural networks", "node": "Nasimeh Heydaribeni", "weight": 1, "attrs": {}}, {"edge": "Distributed constrained combinatorial optimization leveraging hypergraph neural networks", "node": "Xinrui Zhan", "weight": 1, "attrs": {}}, {"edge": "Distributed constrained combinatorial optimization leveraging hypergraph neural networks", "node": "Ruisi Zhang", "weight": 1, "attrs": {}}, {"edge": "Distributed constrained combinatorial optimization leveraging hypergraph neural networks", "node": "Tina Eliassi-Rad", "weight": 1, "attrs": {}}, {"edge": "Distributed constrained combinatorial optimization leveraging hypergraph neural networks", "node": "Farinaz Koushanfar", "weight": 1, "attrs": {}}, {"edge": "Multi-Modal Temporal Hypergraph Neural Network for Flotation Condition Recognition", "node": "Zunguan Fan", "weight": 1, "attrs": {}}, {"edge": "Multi-Modal Temporal Hypergraph Neural Network for Flotation Condition Recognition", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Multi-Modal Temporal Hypergraph Neural Network for Flotation Condition Recognition", "node": "Kang Wang", "weight": 1, "attrs": {}}, {"edge": "Multi-Modal Temporal Hypergraph Neural Network for Flotation Condition Recognition", "node": "Xiaoli Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-View Action Recognition Using Event Cameras", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-View Action Recognition Using Event Cameras", "node": "Jiaxuan Lu", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-View Action Recognition Using Event Cameras", "node": "Siqi Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-View Action Recognition Using Event Cameras", "node": "Yipeng Li", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-View Action Recognition Using Event Cameras", "node": "Shaoyi Du", "weight": 1, "attrs": {}}, {"edge": "Divide-Aggregate Heterogeneous Hypergraph for large-scale user intention detection", "node": "Mingcheng Qu", "weight": 1, "attrs": {}}, {"edge": "Divide-Aggregate Heterogeneous Hypergraph for large-scale user intention detection", "node": "Xianyang Song", "weight": 1, "attrs": {}}, {"edge": "Divide-Aggregate Heterogeneous Hypergraph for large-scale user intention detection", "node": "Donglin Di", "weight": 1, "attrs": {}}, {"edge": "Divide-Aggregate Heterogeneous Hypergraph for large-scale user intention detection", "node": "Tonghua Su", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "node": "Yihe Luo", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Multi-View Time-Series Hypergraph Neural Network for Action Recognition", "node": "Nan Ma", "weight": 1, "attrs": {}}, {"edge": "Multi-View Time-Series Hypergraph Neural Network for Action Recognition", "node": "Zhixuan Wu", "weight": 1, "attrs": {}}, {"edge": "Multi-View Time-Series Hypergraph Neural Network for Action Recognition", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Multi-View Time-Series Hypergraph Neural Network for Action Recognition", "node": "Cheng Wang", "weight": 1, "attrs": {}}, {"edge": "Multi-View Time-Series Hypergraph Neural Network for Action Recognition", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "node": "Yifan Feng", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "node": "Shuyi Ji", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "node": "Yu-Shen Liu", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "node": "Shaoyi Du", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "node": "Qionghai Dai", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Based Multi-Modal Representation for Open-Set 3D Object Retrieval", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Yuze Liu", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Ziming Zhao", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Tiehua Zhang", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Kang Wang", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Xin Chen", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Xiaowei Huang", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Jun Yin", "weight": 1, "attrs": {}}, {"edge": "Exploiting Spatial-Temporal Data for Sleep Stage Classification via Hypergraph Learning", "node": "Zhishu Shen", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "node": "Bingjun Luo", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "node": "Haowen Wang", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "node": "Jinpeng Wang", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "node": "Junjie Zhu", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "node": "Xibin Zhao", "weight": 1, "attrs": {}}, {"edge": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition", "node": "Yue Gao", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Lu Jiang", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Yanan Xiao", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Xinxin Zhao", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Yuanbo Xu", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Shuli Hu", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Pengyang Wang", "weight": 1, "attrs": {}}, {"edge": "Hierarchical Reinforcement Learning on Multi-Channel Hypergraph Neural Network for Course Recommendation", "node": "Minghao Yin", "weight": 1, "attrs": {}}, {"edge": "Strong Consistency of Spectral Clustering for the Sparse Degree-Corrected Hypergraph Stochastic Block Model", "node": "Chong Deng", "weight": 1, "attrs": {}}, {"edge": "Strong Consistency of Spectral Clustering for the Sparse Degree-Corrected Hypergraph Stochastic Block Model", "node": "Xin-Jian Xu", "weight": 1, "attrs": {}}, {"edge": "Strong Consistency of Spectral Clustering for the Sparse Degree-Corrected Hypergraph Stochastic Block Model", "node": "Shihui Ying", "weight": 1, "attrs": {}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "node": "Zhaofan Zhang", "weight": 1, "attrs": {}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "node": "Yanan Xiao", "weight": 1, "attrs": {}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "node": "Lu Jiang", "weight": 1, "attrs": {}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "node": "Dingqi Yang", "weight": 1, "attrs": {}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "node": "Minghao Yin", "weight": 1, "attrs": {}}, {"edge": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation", "node": "Pengyang Wang", "weight": 1, "attrs": {}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "node": "Zhixuan Wu", "weight": 1, "attrs": {}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "node": "Nan Ma", "weight": 1, "attrs": {}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "node": "Cheng Wang", "weight": 1, "attrs": {}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "node": "Cheng Xu", "weight": 1, "attrs": {}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "node": "Genbao Xu", "weight": 1, "attrs": {}}, {"edge": "Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition", "node": "Mingxing Li", "weight": 1, "attrs": {}}], "network-type": "undirected", "metadata": {"default_attrs": {"nodes": {"weight": 1, "institutions": null, "attrs": {}}, "edges": {"weight": 1, "abstract": null, "source": null, "tags": null, "funding_agencies": null, "date": null, "attrs": {}}, "incidences": {"weight": 1, "attrs": {}}}, "name": "None:6"}}